# courier-oss
Open source API controlled inference engine for hosting LLMs in production and connecting them to n8n. Connects to the Courier API Platform for remotely managing models.
